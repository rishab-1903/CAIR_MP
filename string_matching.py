import gradio as gr
import json
import store_caption
from sentence_transformers import SentenceTransformer, util
import speech_recognition as sr
from deep_translator import GoogleTranslator

# ‚úÖ Load BERT model for similarity search
bert_model = SentenceTransformer("all-MiniLM-L6-v2")

# ‚úÖ Global storage for captions
captions = {}
image_links = {}

def initialize_captions(folder_id):
    """Fetch captions once and store in JSON file."""
    global captions, image_links

    try:
        # ‚úÖ Call store_caption.py
        num_captions, image_links = store_caption.fetch_and_store_captions(folder_id)

        # ‚úÖ Load stored captions
        with open("captions.json", "r") as f:
            captions = json.load(f)

        return f"‚úÖ {num_captions} captions stored! Ready for searching."

    except Exception as e:
        return f"‚ùå Error initializing captions: {e}"

def search_captions(query):
    """Find top matching captions using BERT similarity search."""
    if not captions:
        return "‚ùå No captions available. Fetch them first!"

    # ‚úÖ Compute query embedding
    query_embedding = bert_model.encode(query, convert_to_tensor=True)

    # ‚úÖ Compute similarity scores
    similarities = []
    for img_name, caption in captions.items():
        caption_embedding = bert_model.encode(caption, convert_to_tensor=True)
        score = util.pytorch_cos_sim(query_embedding, caption_embedding).item()
        similarities.append((img_name, caption, score))

    # ‚úÖ Get top match
    top_matches = sorted(similarities, key=lambda x: x[2], reverse=True)[:1]

    # ‚úÖ Prepare results
    results = []
    for img_name, caption, score in top_matches:
        image_url = image_links.get(img_name, "#")
        results.append(f"üîπ **{caption}** | [View Image]({image_url})")

    return "\n\n".join(results)  

def speech_to_text():
    """Convert speech to text and translate to English."""
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("üéô Speak in Telugu or Hindi... (Auto-stop enabled)")
        recognizer.adjust_for_ambient_noise(source)

        try:
            # Stop listening automatically after 5 seconds of silence or continuous speech
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
            
            # Convert speech to text
            text = recognizer.recognize_google(audio, language="hi-IN")  # Change "te-IN" for Telugu
            print(f"Recognized Text: {text}")

            # Translate to English
            translated_text = GoogleTranslator(source="auto", target="en").translate(text)
            print(f"Translated Text: {translated_text}")
            return translated_text

        except sr.WaitTimeoutError:
            print("‚è≥ No speech detected. Try again.")
            return "No speech detected, please try again."

        except Exception as e:
            print(f"‚ùå Error: {e}")
            return "Could not process audio"
        
# ‚úÖ Gradio UI
with gr.Blocks() as app:
    gr.Markdown("# üì∑ Context Aware Image Retrieval System - Voice & Text Search")

    # ‚úÖ Section 1: Fetch Captions
    with gr.Row():
        folder_id_input = gr.Textbox(label="Google Drive Folder ID", placeholder="Enter folder ID")
        fetch_button = gr.Button("üì• Fetch Captions")

    status_output = gr.Textbox(label="Status", interactive=False)
    fetch_button.click(initialize_captions, inputs=[folder_id_input], outputs=[status_output])

    # ‚úÖ Section 2: Search Captions
    with gr.Row():
        query_input = gr.Textbox(label="üîç Enter search query")
        voice_button = gr.Button("üéô Speak")

    search_button = gr.Button("Search")
    search_output = gr.Markdown()

    # ‚úÖ Voice Search - Convert Speech to Text
    voice_button.click(speech_to_text, outputs=[query_input])

    # ‚úÖ Perform Search
    search_button.click(search_captions, inputs=[query_input], outputs=[search_output])

app.launch()